

## 1. DSCRNN 모델



### 아키텍처
```
Input [B, 1, L]
    ↓
Depthwise Separable Conv Block 1 + MaxPool
    ↓
Depthwise Separable Conv Block 2 + MaxPool 
    ↓
Depthwise Separable Conv Block 3
    ↓
Bidirectional LSTM
    ↓
Fully Connected Layer
    ↓
Output [B, num_classes]
```



#### DCRNNModel
- Conv Layers: 2개 (conv1, conv3)
- Conv Channels: 256 → 128
- LSTM: Hidden 50, 1 layer
- Parameters: ~50K (0.05M)
- 특징: 최소 구성, 가장 빠른 추론 속도

```python
from models import DCRNNModel
model = DCRNNModel(in_channel=1, num_classes=5)
```

```

### 커스텀 모델 생성
```python
from models import DCRNNModel

custom_model = DCRNNModel(
    in_channel=1,
    num_classes=5,
    conv_channels=[96, 192, 384],  # 2개 또는 3개 지정
    lstm_hidden=192,
    lstm_layers=2
)
```

---
## 2. SE-ResNet-LSTM 모델

### 개요
SE-ResNet-LSTM은 Squeeze-and-Excitation ResNet과 LSTM을 결합한 모델입니다.
SE 블록을 통해 채널 간 의존성을 학습하고, Bottleneck 구조로 깊은 네트워크를 효율적으로 구성합니다.

### 아키텍처
```
Input [B, 1, L]
    ↓
Initial Conv (kernel=15, stride=2) + BatchNorm + ReLU + MaxPool
    ↓
SE-ResNet Layer 1 (Bottleneck blocks)
    ↓
SE-ResNet Layer 2 (Bottleneck blocks, stride=2)
    ↓
[Optional] SE-ResNet Layer 3 (Bottleneck blocks, stride=2)
    ↓
LSTM (Bidirectional or Unidirectional)
    ↓
Fully Connected Layer
    ↓
Output [B, num_classes]
```

### 주요 구성 요소

#### Bottleneck Block
- 1x1 Conv (dimension reduction)
- 3x3 Conv (feature extraction)
- 1x1 Conv (dimension expansion, expansion=4)
- SE Layer (channel attention)
- Residual connection

#### SE Layer
- Global Average Pooling
- FC (reduction)
- ReLU
- FC (expansion)
- Sigmoid
- Channel-wise multiplication

### 버전별 사양

#### SEResNetLSTM 
- ResNet Layers: 2개 (layer1, layer2)
- Blocks per Layer: [2, 2]
- Channels: 64 → 128
- LSTM: Hidden 50, 1 layer, Unidirectional
- SE Reduction: 16
- Parameters: ~400K (0.4M)
- 특징: 기본 구성, 빠른 학습

```python
from models import SEResNetLSTM
model = SEResNetLSTM(in_channel=1, num_classes=5)
```

--

### 데이터 전처리 (train.py 전역 변수)

```python
# 세그먼트 길이 조정
segment_seconds = 5.0      # 1초, 3초, 5초 등 자유롭게 설정

# 샘플링 레이트
fs_out = 360               # 360Hz (MIT-BIH 기본값)

# 사용할 ECG 리드
ecg_leads = ['MLII']       # MIT-BIH의 주요 리드
```

### 손실 함수 (train.py 전역 변수)

```python
# lambda_combined로 손실 함수 제어
lambda_combined = 1.0      # CE only
lambda_combined = 0.0      # Proxy only
lambda_combined = 0.5      # Combined (0.5*CE + 0.5*Proxy)

# Proxy Loss 파라미터
proxy_type = 'ProxyAnchorLoss'
proxy_alpha = 32.0
proxy_delta = 0.1
```

### 학습 파라미터

```python
batch_size = 512
nepoch = 50
lr_initial = 1e-4
decay_epoch = 20
```

---

## 5. 모델 테스트

### 모델 파라미터 확인

```python
import torch
from models import DCRNNModel_base, SEResNetLSTM

# 테스트 입력 (5초 @ 360Hz = 1800 samples)
x = torch.randn(2, 1, 1800)

# 모델 생성
model = DCRNNModel_base(in_channel=1, num_classes=5)

# Forward pass
logits, features = model(x, return_features=True)

# 파라미터 수 확인
total_params = sum(p.numel() for p in model.parameters())
print(f"Total Parameters: {total_params:,} ({total_params/1e6:.2f}M)")
print(f"Logits shape: {logits.shape}")      # [2, 5]
print(f"Features shape: {features.shape}")  # [2, feature_dim]
```

### 모델 저장 및 로드

```python
# 저장
torch.save(model.state_dict(), 'model.pth')

# 로드
model = DCRNNModel_base(in_channel=1, num_classes=5)
model.load_state_dict(torch.load('model.pth'))
model.eval()
```

---
